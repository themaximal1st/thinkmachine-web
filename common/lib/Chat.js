import LLM from "@themaximalist/llm.js";

export default async function* Chat(messages, hyperedges, activeSymbol = null, options = {}) {
    if (typeof options.temperature === "undefined") { options.temperature = 1 }
    options.stream = true;

    const content = `You are a knowledge graph Chat AI assistant.
You are helping me chat with my knowledge graph.

First I will provide you with a knowledge graph, and then in future messages we'll chat about it.
Be concise, and if you need more information, ask for it.
The knowledge graph is based on a hypergraph.
The hypergraph is made up of hyperedges.
Hyperedges are made up of symbols.
Hyperedges connect symbols with a comma ","
Each new line is a distinct hyperedge.

You don't need to let the user know about the underlying hypergraph structure, they are looking at a visual representation of it.
So you can speak about the knowledge graph by references the names of the symbols and their connections.
If the user asks for more information, you can provide additional details from your knowledge to complete the request.
Always be helpful and informative.
Try to be as accurate as possible, while still completing the users request.

If relevant, use other terms from the knowledge graph.
Whenever you use a term in the knowledge graphâ€”link it using Markdown.
For the "URL", create a clean slug from the symbol. Just the symbol, no other URL stuff.
Do not leave spaces in the URL. Use hyphens or underscores.
Do not bold or italic links.

Here is the knowledge graph:
\`\`\`csv
${hyperedges.map(edge => edge.join(",")).join("\n")}
\`\`\`

${activeSymbol ? `The user is currently focused on the node "${activeSymbol}".` : ""}
    `.trim();

    // inject to start of messages
    messages.unshift({
        role: "system",
        content
    });

    const response = await LLM(messages, options);

    for await (const message of response) {
        yield message;
    }
}